
# Nathaniel Davis


    AI-ML-Assignment-5-Simple-RAG
For each answer I had it show 2 chunks that it used to form its answer. For question one it grabbed chunk one and two, For answer two it grabbed chunk zero and six. The last question it grabbed chunk fourteen and nine. Each chunk was relevant to the question besides two. I think I could optimize the retrieval process by reducing the chunk sizes and allowing for more chunks to be leveraged.

With my results I beleive the prompting of the LLM with the addition of the RAG made it so that the LLM gave higher quality and relevant answers with reducing the hallucinations given out and I can directly see that with  Question 2 not giving a fake answer.

    Youtube Link: https://youtu.be/JvrIilrF7lM